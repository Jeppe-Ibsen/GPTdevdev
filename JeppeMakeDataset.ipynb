{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOh9y0eZYiTiF6UTEeb7Bn5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeppe-Ibsen/GPTdevdev/blob/master/JeppeMakeDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "izQ20p6qKHJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "sZwHLJ4BG9HS",
        "outputId": "1457eb5c-80b3-43bc-cd64-d8e37daadc76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I will make the entire audience disappear before your eyes\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTodo: Implement error handling for API requests and file operations.\\nConsider adding logging to track API requests, responses, and errors for debugging purposes.\\nUnit test\\nSet up CI/CD pipelines (e.g., GitHub Actions) for automated testing and deployment.\\nMock the OpenAI API response and ensure the function correctly extracts and returns the response text.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import openai\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "openai.organization = \"org-WIgpZh4xRqpQ3g9sxXRvHRQz\"\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def make_openai_request(prompt):\n",
        "  completion = openai.ChatCompletion.create(\n",
        "\n",
        "\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  max_tokens=10,\n",
        "  messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "  )\n",
        "  return print(completion.choices[0].message.content)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "make_openai_request(\"In 10 tokens, compelete the following: And for my next magic trick, \")\n",
        "\n",
        "#To see how many tokens are used by an API call, check the usage field in the API response (e.g., response['usage']['total_tokens']).\n",
        "#Max: 4097 tokens for gpt-3.5-turbo (input included)\n",
        "\"\"\"\n",
        "def make_openai_request(prompt):\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"davinci\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=50  # Adjust as needed\n",
        "    )\n",
        "    return response.choices[0].text\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "Todo: Implement error handling for API requests and file operations.\n",
        "Consider adding logging to track API requests, responses, and errors for debugging purposes.\n",
        "Unit test\n",
        "Set up CI/CD pipelines (e.g., GitHub Actions) for automated testing and deployment.\n",
        "Mock the OpenAI API response and ensure the function correctly extracts and returns the response text.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Create an HTTP endpoint using Flask\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/generate\", methods=[\"POST\"])\n",
        "def generate_response():\n",
        "    data = request.get_json()\n",
        "    prompt = data.get(\"prompt\", \"\")\n",
        "    response_text = make_openai_request(prompt)\n",
        "    return jsonify({\"response\": response_text})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"localhost\", port=5000)\n",
        "\n",
        "\"\"\"\n",
        "Unit test\n",
        "Simulate an API request to the Flask endpoint and verify that it returns a valid response.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "OZJk0lU7HviM",
        "outputId": "298a454a-8fd8-4807-934e-be40788ab079"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://localhost:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nUnit test\\nSimulate an API request to the Flask endpoint and verify that it returns a valid response.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def append_to_dataset(response_text, dataset_file):\n",
        "    with open(dataset_file, \"a\") as file:\n",
        "        file.write(response_text + \"\\n\")\n",
        "\"\"\"\n",
        "Unit test\n",
        "Create a temporary dataset file, append some text to it using the function, and then read the file to ensure the appended text is present.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "g3QCljQuHuDz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}