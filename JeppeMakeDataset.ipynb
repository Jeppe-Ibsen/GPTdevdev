{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+62OvkFTYTCFy6CbxWBQd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeppe-Ibsen/GPTdevdev/blob/master/JeppeMakeDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "try:\n",
        "  !mkdir Jeppe_temp_folder\n",
        "except:\n",
        "  print(\"Folder already exists\")\n",
        "print(\"done\")"
      ],
      "metadata": {
        "id": "izQ20p6qKHJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab0ac92-6959-4a40-8da2-ad78cf605d29"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.1\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wonderwords"
      ],
      "metadata": {
        "id": "NntFymYe6usU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "513b680d-4181-4991-f96a-3819602adb4b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wonderwords\n",
            "  Downloading wonderwords-2.2.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wonderwords\n",
            "Successfully installed wonderwords-2.2.0\n",
            "Requirement already satisfied: wonderwords in /usr/local/lib/python3.10/dist-packages (2.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wonderwords\n",
        "from wonderwords import RandomWord\n",
        "#https://pypi.org/project/wonderwords/\n",
        "#https://wonderwords.readthedocs.io\n",
        "#a random noun or adjective, by default all parts of speech are included\n",
        "#r.word(include_parts_of_speech=[\"nouns\", \"adjectives\"])\n",
        "\n",
        "# generate a random word between the length of 3 and 8 characters\n",
        "#r.word(word_min_length=3, word_max_length=8)\n",
        "\n",
        "generator = RandomWord()\n",
        "generator.word(include_parts_of_speech=[\"nouns\"])\n",
        "\n",
        "from wonderwords import Sentence\n",
        "s = sentence()"
      ],
      "metadata": {
        "id": "X_eKu8kI62fT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "46d099cb-b155-45d1-a35f-736e2daf8081"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The modern miss structures provision.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import time\n",
        "import random\n",
        "\n",
        "openai.organization = \"org-WIgpZh4xRqpQ3g9sxXRvHRQz\"\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def make_openai_request(prompt):\n",
        "\n",
        "  completion = openai.ChatCompletion.create(\n",
        "\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  max_tokens= 800,\n",
        "  temperature= 0.7,\n",
        "  n= 1,\n",
        "\n",
        "  messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "  )\n",
        "\n",
        "  return completion.choices[0].message.content\n",
        "\n",
        "def generate_unique_filename(path=\"\"):\n",
        "    \"\"\"Generate a unique filename using a timestamp.\"\"\"\n",
        "    timestamp = int(time.time())\n",
        "    humanword = generator.word(include_parts_of_speech=[\"nouns\"])\n",
        "    filename = f\"dataset_{timestamp}_{humanword}.txt\"\n",
        "    return path + filename\n",
        "\n",
        "custom_path = \"/content/Jeppe_temp_folder/\"\n",
        "num_requests = 3                            #this will be alot larger soon\n",
        "dataset_file = generate_unique_filename()  # Create a unique dataset file\n",
        "\n",
        "print(f\"Generating dataset in file: {dataset_file}\")\n",
        "\n",
        "with open(dataset_file, \"a\") as f:\n",
        "        for _ in range(num_requests):\n",
        "            word_to_insert = random.choice([\"Avoidance\", \"Projection\", \"Sublimation\"])  # Replace with your list of words\n",
        "            #word_to_insert = generator.word(include_categories=[\"noun\"])\n",
        "            sentence_to_insert = s.sentence()\n",
        "            ending_insert =  random.choice([\"bad\", \"good\", \"surprising\"])  # Replace with your list of words\n",
        "            preprompt = f\"Use the text as inspiration to do a one-line story about a small conflict situation with at least one person involved. Do it so a 14-year old would understand it. Make the story have a {ending_insert} ending. A person in the story, whom has a fitting name, uses the following psychological defense mechanism: {word_to_insert}, but make sure to not mention it. Do however make sure it's used accurately and portrayed in a brutal and realistic way. Also don't mention arguments.\"\n",
        "            #prompt = f\"The cat sat on the {word_to_insert}.\" #formatted string literal (f-string) in Python. It allows you to embed expressions inside string literals, using curly braces {} to enclose expressions\n",
        "            prompt = f\"{preprompt}: '''{sentence_to_insert}'''\"\n",
        "            print(f\"Using prompt: {prompt}\")\n",
        "            response = f\"{make_openai_request(prompt)} [{word_to_insert}]\"\n",
        "            print(f\"Received response: {response}\")\n",
        "            f.write(response + \"\\n\")  # Append each response as a new line\n",
        "\n",
        "print(\"Dataset generation complete.\")"
      ],
      "metadata": {
        "id": "cQBQBiVn6RXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf555754-a125-49e2-fc56-ba6cb1dd118e"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating dataset in file: dataset_1696628343_tripod.txt\n",
            "Using prompt: Use the text as inspiration to do a one-line story about a small conflict situation with at least one person involved. Do it so a 14-year old would understand it. Make the story have a good ending. A person in the story, whom has a fitting name, uses the following psychological defense mechanism: Projection, but make sure to not mention it. Do however make sure it's used accurately and portrayed in a brutal and realistic way. Also don't mention arguments.: '''The gaudy hold flees sickness.'''\n",
            "Received response: When Jake accidentally broke Lily's favorite vase, he blamed it on his little sister, hoping to avoid getting in trouble, but his guilty conscience gnawed at him until he confessed, and together they found a way to fix the vase, strengthening their bond. [Projection]\n",
            "Using prompt: Use the text as inspiration to do a one-line story about a small conflict situation with at least one person involved. Do it so a 14-year old would understand it. Make the story have a surprising ending. A person in the story, whom has a fitting name, uses the following psychological defense mechanism: Avoidance, but make sure to not mention it. Do however make sure it's used accurately and portrayed in a brutal and realistic way. Also don't mention arguments.: '''The weak piety rots mixer.'''\n",
            "Received response: As the timid Timmy tried to fix the broken blender, his older sister Sarah watched with a smirk, knowing she could avoid helping and enjoy a smoothie instead. [Avoidance]\n",
            "Using prompt: Use the text as inspiration to do a one-line story about a small conflict situation with at least one person involved. Do it so a 14-year old would understand it. Make the story have a bad ending. A person in the story, whom has a fitting name, uses the following psychological defense mechanism: Avoidance, but make sure to not mention it. Do however make sure it's used accurately and portrayed in a brutal and realistic way. Also don't mention arguments.: '''The black puggle guards cucumber.'''\n",
            "Received response: As the black puggle guarded the cucumber, it unintentionally ignored the pleas for help from its owner who was choking on a piece, leading to a tragic ending. [Avoidance]\n",
            "Dataset generation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5tvj0gb8hXXS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}